{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据文本来剪辑视频\n",
    "\n",
    "程序依赖\n",
    "\n",
    "* srt https://github.com/cdown/srt\n",
    "* webvtt-py https://github.com/glut23/webvtt-py\n",
    "\n",
    "来处理字幕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srt # https://github.com/cdown/srt\n",
    "import webvtt # https://github.com/glut23/webvtt-py\n",
    "import os\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import subprocess\n",
    "import argparse\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from sub2txt import sub_to_df, df_to_txt,get_sub_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果没有编辑txt文本来生成摘要，那么就没有必要去对视频进行剪辑，否则按照现在的做法会把整个视频切分成一句一句再合并起来。\n",
    "所以需要判断一个评分，看看字幕文件和txt文本之间是否有足够的内容差别。\n",
    "\n",
    "difflib.SequenceMatcher(None, text1, text2).quick_ratio()可以快速生成两个文本之间相似程度的评分，如果高于阈值，就不必进行后续剪辑的处理了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_score(df, txt):\n",
    "    '''\n",
    "    比较字幕文件和summary文件是否有差异，如果差异太小，后续则不做视频剪辑处理\n",
    "    '''\n",
    "    df_txt=df_to_txt(df)\n",
    "    s=difflib.SequenceMatcher(None, df_txt, txt) \n",
    "    return(s.quick_ratio())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在路径中找到与输入文件名最接近的文件名\n",
    "\n",
    "difflib.SequenceMatcher(None, text1, text2).ratio()可以快速生成两个文本之间相似程度的评分，用这个来找到目录中最相似的文件名。因为字幕文件往往会带有语言标记，比如.zh-CN.srt之类，懒得去一步一步判断了，直接用评分来比较好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_simliar_filename(target_filename, path, ext):\n",
    "    '''\n",
    "    在路径中找到与输入文件名最接近的文件名\n",
    "    '''\n",
    "    candidate=get_sub_files(path,[],ext)\n",
    "    simliar_score=[difflib.SequenceMatcher(None,c,target_filename).ratio() for c in candidate]\n",
    "    max_index=simliar_score.index(max(simliar_score))\n",
    "    return(candidate[max_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在字幕df中，一句一句寻找text中的内容，将最接近的挑出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_in_df(text,df):\n",
    "    '''\n",
    "    '''\n",
    "    chosen_text=[]\n",
    "    for t in text.splitlines():\n",
    "        sentence=difflib.get_close_matches(t,df[\"text\"],n=1)\n",
    "        if sentence:\n",
    "            chosen_text.extend(sentence)\n",
    "    df_chosen=pd.DataFrame(chosen_text,columns=[\"text\"])\n",
    "    df_chosen=df_chosen.merge(df)\n",
    "    return df_chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重建字幕\n",
    "\n",
    "挑出来的字幕数据，想重建成一个新的字幕文件，但是挑选出来的字幕数据，时间戳是原来的时间，需要合并到一起，那么先计算每一句话花了多少时间，再累积起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_sub(df_chosen,output_filename):\n",
    "    df_chosen[\"delta_time\"]=pd.to_datetime(df_chosen[\"end\"])-pd.to_datetime(df_chosen[\"start\"])\n",
    "    df_chosen[\"new_end\"]=df_chosen[\"delta_time\"].cumsum()\n",
    "    df_chosen[\"new_start\"]=df_chosen[\"new_end\"]-df_chosen[\"delta_time\"]\n",
    "    new_sub_df=df_chosen[[\"new_start\",\"new_end\",\"text\"]]\n",
    "\n",
    "    subs=[srt.Subtitle(index=i,\n",
    "                 start=new_sub_df.new_start[i], \n",
    "                 end= new_sub_df.new_end[i], \n",
    "                 content=new_sub_df.text[i])\n",
    "          for i in range(len(new_sub_df))]\n",
    "    srt_content=srt.compose(subs)\n",
    "    # 写入output_filename的同名srt文件\n",
    "    base_name,ext=os.path.splitext(output_filename)\n",
    "    srt_file_name=base_name+\".srt\"\n",
    "    with open(srt_file_name,\"w\") as f:\n",
    "        f.write(srt_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用ffmpeg来根据起止时间剪辑视频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_video(video_filename, start, end,output_filename):\n",
    "    ffmpeg_command=['ffmpeg',\n",
    "         '-ss',start,\n",
    "         '-i',\n",
    "         video_filename,\n",
    "         '-to', end,\n",
    "         '-c:v', 'libx264', '-c:a', 'libmp3lame', #视频重编码使用x264, 音频重编码使用mp3\n",
    "         '-copyts', # 强制使用原视频的绝对时间\n",
    "         '-y', # 强制覆盖\n",
    "         output_filename]\n",
    "    p=subprocess.run(ffmpeg_command, shell=False, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    return(p.stdout.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_video_by_keynote(df, video_filename, final_output):\n",
    "    # 产生临时目录，with完成后自动销毁\n",
    "    with TemporaryDirectory() as temp_path:\n",
    "        #临时文件命名, 记录临时文件列表\n",
    "        temp_file_list=[os.path.join(temp_path,\"tmp_{}.mp4\".format(index)) for index in range(len(df))]\n",
    "        temp_input=os.path.join(temp_path,'tmp_input_files.txt')\n",
    "        with open(temp_input,'w') as f:\n",
    "            for index in range(len(df)):\n",
    "                f.write(\"file '{}'\\n\".format(temp_file_list[index]))    \n",
    "    \n",
    "        # 遍历数据库, 下载每个视频片段\n",
    "        for index, row in df.iterrows():\n",
    "            clip_video(video_filename, row.start, row.end,temp_file_list[index])\n",
    "\n",
    "        # 将临时文件合并起来\n",
    "        ff_concat_command=[\"ffmpeg\", \n",
    "                       '-f','concat',\n",
    "                       '-safe','0',\n",
    "                       '-i', temp_input,\n",
    "                       '-c:v', 'copy', '-c:a', 'copy', '-copyts', #合并似乎不需要重新编码\n",
    "                       '-y',\n",
    "                       final_output # final_output的路径并不在temp目录下，所以不会被销毁\n",
    "                       ]\n",
    "        ff=subprocess.run(ff_concat_command, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return ff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_one(txt_file, srt_file, video_file, output_file, threshold=0.8):\n",
    "    print(\"{}\".format(os.path.basename(video_file)))\n",
    "    with open(txt_file,\"r\") as f:\n",
    "        txt=f.read()\n",
    "    df_ori=sub_to_df(srt_file)\n",
    "    \n",
    "    if summary_score(df_ori,txt)> threshold: # 太接近，没必要进行剪辑了。\n",
    "        print(\"...Pass \")\n",
    "        return \n",
    "    df_chosen=find_text_in_df(txt,df_ori)\n",
    "    clip_video_by_keynote(df_chosen, video_file, output_file)\n",
    "    rebuild_sub(df_chosen,output_file)\n",
    "    print(\"...Done \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_path(path):\n",
    "    # 找到path下所有的txt文件\n",
    "    txt_file_list=get_sub_files(path,[],\"txt\")\n",
    "    # 找到path下与txt文件名最接近的字幕文件\n",
    "    sub_file_list=[get_most_simliar_filename(t, path, (\"srt\",\"vtt\")) for t in txt_file_list]\n",
    "    # 找到path下与txt文件名最接近的视频文件\n",
    "    video_file_list=[get_most_simliar_filename(t, path, (\"mp4\",\"mov\")) for t in txt_file_list]\n",
    "    \n",
    "    for t,s,v in zip(txt_file_list,sub_file_list,video_file_list):\n",
    "        o=os.path.join(os.path.dirname(v),\"summary_\"+os.path.basename(v))\n",
    "        clip_one(t, s, v, o, threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义命令行参数, 必要时可以指定这些文件，否则默认为输入的是txt文件或者是路径。\n",
    "* -s 字幕文件\n",
    "* -v 视频文件\n",
    "* -o 输出文件\n",
    "\n",
    "如果输入的是目录路径，则遍历其下所有txt文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_parse():\n",
    "    '''\n",
    "    解析命令行参数\n",
    "    '''\n",
    "    # 创建解析步骤\n",
    "    parser = argparse.ArgumentParser(description='Clip video based on txt summary file.')\n",
    "\n",
    "    # 添加参数步骤\n",
    "    parser.add_argument(\"input\", type=str,\n",
    "                       help=\"a txt file or a path.\")\n",
    "    \n",
    "    \n",
    "#     parser.add_argument('-t','--txt',  type=str, \n",
    "#                        help='txt file, the summary')\n",
    "#     parser.add_argument('-p','--path',  type=str, \n",
    "#                        help='path')\n",
    "    \n",
    "    \n",
    "    parser.add_argument('-s','--sub',  type=str, \n",
    "                       help='subtitle file')    \n",
    "    parser.add_argument('-v','--video',  type=str, \n",
    "                       help='video file')\n",
    "    parser.add_argument('-o','--output',  type=str, \n",
    "                       help='output video file')\n",
    "\n",
    "\n",
    "    # 解析参数步骤  \n",
    "    args = parser.parse_args()\n",
    "    return(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    args=arg_parse()\n",
    "    sub_format=(\"srt\",\"vtt\")\n",
    "    video_format=(\"mp4\",\"mov\",\"mkv\")\n",
    "    \n",
    "    if os.path.isfile(args.input): # 处理单个文件\n",
    "        \n",
    "        path=os.path.dirname(args.input)\n",
    "        if path==\"\": # 如果是本地目录\n",
    "            path=os.path.abspath(os.path.dirname(__file__))\n",
    "        if args.sub==None:\n",
    "            args.sub=get_most_simliar_filename(args.input, path, sub_format)\n",
    "        if args.video==None:\n",
    "            args.video=get_most_simliar_filename(args.input, path, video_format)\n",
    "        if args.output==None:\n",
    "            v=args.video\n",
    "            args.output=os.path.join(os.path.dirname(v),\"summary_\"+os.path.basename(v))\n",
    "        \n",
    "        clip_one(args.input, args.sub, args.video, args.output,threshold=0.8)\n",
    "        \n",
    "    elif os.path.isdir(args.input): # 处理目录下所有txt文件\n",
    "        clip_path(args.input)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
